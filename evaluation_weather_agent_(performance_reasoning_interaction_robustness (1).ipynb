{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UyFEBCNPr0pN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df6105cc-a0b9-48b8-9201-a40ba20fcff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ollama\n",
            "  Downloading ollama-0.5.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.12/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.12/dist-packages (from ollama) (2.11.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
            "Downloading ollama-0.5.3-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: ollama\n",
            "Successfully installed ollama-0.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install ollama requests python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from typing import Dict, Any, Optional, List, Tuple\n",
        "from datetime import datetime\n",
        "import statistics"
      ],
      "metadata": {
        "id": "XBlzZUZfr-ES"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WeatherAgentMetrics:\n",
        "    \"\"\"Evaluation metrics for the weather agent\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset_metrics()\n",
        "\n",
        "    def reset_metrics(self):\n",
        "        \"\"\"Reset all metrics\"\"\"\n",
        "        self.task_metrics = {\n",
        "            'total_requests': 0,\n",
        "            'successful_requests': 0,\n",
        "            'failed_requests': 0,\n",
        "            'response_times': [],\n",
        "            'accuracy_scores': []\n",
        "        }\n",
        "\n",
        "        self.reasoning_metrics = {\n",
        "            'city_extraction_success': 0,\n",
        "            'city_extraction_attempts': 0,\n",
        "            'context_understanding': [],\n",
        "            'response_relevance': []\n",
        "        }\n",
        "\n",
        "        self.communication_metrics = {\n",
        "            'response_lengths': [],\n",
        "            'clarity_scores': [],\n",
        "            'helpfulness_scores': [],\n",
        "            'user_satisfaction': []\n",
        "        }\n",
        "\n",
        "        self.autonomy_metrics = {\n",
        "            'error_recovery_attempts': 0,\n",
        "            'error_recovery_success': 0,\n",
        "            'fallback_usage': 0,\n",
        "            'api_error_handling': 0\n",
        "        }\n",
        "\n",
        "class WeatherAgent:\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        self.api_key = api_key or \"your_openweather_api_key_here\"\n",
        "        self.base_url = \"http://api.openweathermap.org/data/2.5\"\n",
        "\n",
        "    def get_weather_data(self, city: str, country: str = \"\") -> Tuple[Dict[str, Any], float]:\n",
        "        \"\"\"Fetch current weather data for a city with timing\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            location = f\"{city},{country}\" if country else city\n",
        "            url = f\"{self.base_url}/weather\"\n",
        "            params = {\n",
        "                \"q\": location,\n",
        "                \"appid\": self.api_key,\n",
        "                \"units\": \"metric\"\n",
        "            }\n",
        "\n",
        "            response = requests.get(url, params=params)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            response_time = time.time() - start_time\n",
        "            return response.json(), response_time\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            response_time = time.time() - start_time\n",
        "            return {\"error\": f\"API request failed: {str(e)}\"}, response_time\n",
        "        except Exception as e:\n",
        "            response_time = time.time() - start_time\n",
        "            return {\"error\": f\"Unexpected error: {str(e)}\"}, response_time\n",
        "\n",
        "class OllamaWeatherAgent:\n",
        "    def __init__(self, model_name: str = \"llama3.1\", weather_api_key: Optional[str] = None):\n",
        "        self.model_name = model_name\n",
        "        self.weather_agent = WeatherAgent(weather_api_key)\n",
        "        self.metrics = WeatherAgentMetrics()\n",
        "        self.setup_model()\n",
        "\n",
        "    def setup_model(self):\n",
        "        \"\"\"Download and setup the Ollama model\"\"\"\n",
        "        try:\n",
        "            print(f\"Pulling {self.model_name} model...\")\n",
        "            ollama.pull(self.model_name)\n",
        "            print(f\"Model {self.model_name} ready!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up model: {e}\")\n",
        "            self.model_name = \"llama3.1:8b\"\n",
        "            ollama.pull(self.model_name)\n",
        "            self.metrics.autonomy_metrics['error_recovery_attempts'] += 1\n",
        "            self.metrics.autonomy_metrics['error_recovery_success'] += 1\n",
        "\n",
        "    def format_weather_data(self, weather_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"Format weather data into readable text\"\"\"\n",
        "        if \"error\" in weather_data:\n",
        "            self.metrics.autonomy_metrics['api_error_handling'] += 1\n",
        "            return f\"Weather data error: {weather_data['error']}\"\n",
        "\n",
        "        try:\n",
        "            city = weather_data[\"name\"]\n",
        "            country = weather_data[\"sys\"][\"country\"]\n",
        "            temp = weather_data[\"main\"][\"temp\"]\n",
        "            feels_like = weather_data[\"main\"][\"feels_like\"]\n",
        "            humidity = weather_data[\"main\"][\"humidity\"]\n",
        "            description = weather_data[\"weather\"][0][\"description\"]\n",
        "            wind_speed = weather_data[\"wind\"][\"speed\"]\n",
        "\n",
        "            formatted = f\"\"\"\n",
        "Current Weather for {city}, {country}:\n",
        "- Temperature: {temp}¬∞C (feels like {feels_like}¬∞C)\n",
        "- Condition: {description.title()}\n",
        "- Humidity: {humidity}%\n",
        "- Wind Speed: {wind_speed} m/s\n",
        "\"\"\"\n",
        "            return formatted.strip()\n",
        "        except KeyError as e:\n",
        "            self.metrics.autonomy_metrics['api_error_handling'] += 1\n",
        "            return f\"Error parsing weather data: Missing key {e}\"\n",
        "\n",
        "    def analyze_weather_with_llm(self, weather_data: str, user_query: str) -> Tuple[str, Dict[str, float]]:\n",
        "        \"\"\"Use Ollama LLM to analyze weather and provide insights with metrics\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a helpful weather assistant. Based on the following weather data, please provide a helpful response to the user's query.\n",
        "\n",
        "Weather Data:\n",
        "{weather_data}\n",
        "\n",
        "User Query: {user_query}\n",
        "\n",
        "Please provide:\n",
        "1. A direct answer to their question\n",
        "2. Any relevant advice (clothing, activities, etc.)\n",
        "3. Keep the response conversational and helpful\n",
        "\n",
        "Response:\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = ollama.generate(\n",
        "                model=self.model_name,\n",
        "                prompt=prompt,\n",
        "                options={\n",
        "                    \"temperature\": 0.7,\n",
        "                    \"max_tokens\": 300\n",
        "                }\n",
        "            )\n",
        "\n",
        "            response_time = time.time() - start_time\n",
        "            response_text = response['response']\n",
        "\n",
        "            # Calculate metrics\n",
        "            metrics = {\n",
        "                'response_time': response_time,\n",
        "                'response_length': len(response_text),\n",
        "                'relevance_score': self.calculate_relevance_score(response_text, user_query),\n",
        "                'clarity_score': self.calculate_clarity_score(response_text)\n",
        "            }\n",
        "\n",
        "            return response_text, metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            self.metrics.autonomy_metrics['error_recovery_attempts'] += 1\n",
        "            fallback_response = f\"I encountered an error analyzing the weather data, but here's what I can tell you: {weather_data}\"\n",
        "            self.metrics.autonomy_metrics['fallback_usage'] += 1\n",
        "\n",
        "            response_time = time.time() - start_time\n",
        "            metrics = {\n",
        "                'response_time': response_time,\n",
        "                'response_length': len(fallback_response),\n",
        "                'relevance_score': 0.5,  # Lower score for fallback\n",
        "                'clarity_score': 0.6\n",
        "            }\n",
        "\n",
        "            return fallback_response, metrics\n",
        "\n",
        "    def extract_city_from_query(self, user_input: str) -> Tuple[str, bool]:\n",
        "        \"\"\"Extract city from user input with success tracking\"\"\"\n",
        "        city_extraction_prompt = f\"\"\"\n",
        "Extract the city name from this weather query. If no city is mentioned, return \"unknown\".\n",
        "Only return the city name, nothing else.\n",
        "\n",
        "Query: {user_input}\n",
        "\n",
        "City:\n",
        "\"\"\"\n",
        "\n",
        "        self.metrics.reasoning_metrics['city_extraction_attempts'] += 1\n",
        "\n",
        "        try:\n",
        "            city_response = ollama.generate(\n",
        "                model=self.model_name,\n",
        "                prompt=city_extraction_prompt,\n",
        "                options={\"temperature\": 0.1, \"max_tokens\": 20}\n",
        "            )\n",
        "\n",
        "            city = city_response['response'].strip().lower()\n",
        "\n",
        "            if city != \"unknown\" and city:\n",
        "                self.metrics.reasoning_metrics['city_extraction_success'] += 1\n",
        "                return city, True\n",
        "            else:\n",
        "                return \"unknown\", False\n",
        "\n",
        "        except Exception as e:\n",
        "            return \"unknown\", False\n",
        "\n",
        "    def calculate_relevance_score(self, response: str, query: str) -> float:\n",
        "        \"\"\"Calculate how relevant the response is to the query\"\"\"\n",
        "        query_words = set(query.lower().split())\n",
        "        response_words = set(response.lower().split())\n",
        "\n",
        "        # Simple relevance based on word overlap\n",
        "        common_words = query_words.intersection(response_words)\n",
        "        if len(query_words) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        base_score = len(common_words) / len(query_words)\n",
        "\n",
        "        # Boost score if response contains weather-related terms\n",
        "        weather_terms = {'weather', 'temperature', 'rain', 'sunny', 'cloudy', 'wind', 'humidity'}\n",
        "        weather_overlap = weather_terms.intersection(response_words)\n",
        "        weather_boost = len(weather_overlap) * 0.1\n",
        "\n",
        "        return min(1.0, base_score + weather_boost)\n",
        "\n",
        "    def calculate_clarity_score(self, response: str) -> float:\n",
        "        \"\"\"Calculate clarity score based on response structure\"\"\"\n",
        "        sentences = response.split('.')\n",
        "        avg_sentence_length = statistics.mean([len(s.split()) for s in sentences if s.strip()])\n",
        "\n",
        "        # Optimal sentence length is around 15-20 words\n",
        "        if 10 <= avg_sentence_length <= 25:\n",
        "            length_score = 1.0\n",
        "        else:\n",
        "            length_score = max(0.3, 1.0 - abs(avg_sentence_length - 17.5) * 0.02)\n",
        "\n",
        "        # Check for structure indicators\n",
        "        structure_indicators = ['1.', '2.', '3.', '-', 'advice', 'recommend']\n",
        "        structure_score = min(1.0, sum(1 for indicator in structure_indicators if indicator in response.lower()) * 0.2)\n",
        "\n",
        "        return (length_score + structure_score) / 2\n",
        "\n",
        "    def chat_about_weather(self, user_input: str) -> Tuple[str, Dict[str, Any]]:\n",
        "        \"\"\"Main chat function with comprehensive metrics\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Update task metrics\n",
        "        self.metrics.task_metrics['total_requests'] += 1\n",
        "\n",
        "        # Extract city\n",
        "        city, extraction_success = self.extract_city_from_query(user_input)\n",
        "\n",
        "        if not extraction_success:\n",
        "            response = \"I'd be happy to help with weather information! Could you please specify which city you'd like to know about?\"\n",
        "            self.metrics.task_metrics['failed_requests'] += 1\n",
        "\n",
        "            return response, {\n",
        "                'success': False,\n",
        "                'reason': 'city_extraction_failed',\n",
        "                'response_time': time.time() - start_time\n",
        "            }\n",
        "\n",
        "        # Get weather data\n",
        "        weather_data, api_response_time = self.weather_agent.get_weather_data(city)\n",
        "\n",
        "        if \"error\" in weather_data:\n",
        "            self.metrics.task_metrics['failed_requests'] += 1\n",
        "            return f\"Sorry, I couldn't get weather data for {city}. {weather_data['error']}\", {\n",
        "                'success': False,\n",
        "                'reason': 'api_error',\n",
        "                'response_time': time.time() - start_time\n",
        "            }\n",
        "\n",
        "        # Format weather data\n",
        "        formatted_weather = self.format_weather_data(weather_data)\n",
        "\n",
        "        # Generate LLM response\n",
        "        response, llm_metrics = self.analyze_weather_with_llm(formatted_weather, user_input)\n",
        "\n",
        "        # Update metrics\n",
        "        total_response_time = time.time() - start_time\n",
        "        self.metrics.task_metrics['successful_requests'] += 1\n",
        "        self.metrics.task_metrics['response_times'].append(total_response_time)\n",
        "\n",
        "        # Communication metrics\n",
        "        self.metrics.communication_metrics['response_lengths'].append(llm_metrics['response_length'])\n",
        "        self.metrics.communication_metrics['clarity_scores'].append(llm_metrics['clarity_score'])\n",
        "\n",
        "        # Reasoning metrics\n",
        "        self.metrics.reasoning_metrics['response_relevance'].append(llm_metrics['relevance_score'])\n",
        "\n",
        "        # Calculate accuracy (simplified - based on successful API response and relevant response)\n",
        "        accuracy = 1.0 if llm_metrics['relevance_score'] > 0.7 else 0.8\n",
        "        self.metrics.task_metrics['accuracy_scores'].append(accuracy)\n",
        "\n",
        "        return response, {\n",
        "            'success': True,\n",
        "            'response_time': total_response_time,\n",
        "            'api_response_time': api_response_time,\n",
        "            'llm_response_time': llm_metrics['response_time'],\n",
        "            'relevance_score': llm_metrics['relevance_score'],\n",
        "            'clarity_score': llm_metrics['clarity_score'],\n",
        "            'accuracy': accuracy\n",
        "        }\n",
        "\n",
        "    def get_performance_report(self) -> Dict[str, Any]:\n",
        "        \"\"\"Generate comprehensive performance report\"\"\"\n",
        "        task_metrics = self.metrics.task_metrics\n",
        "        reasoning_metrics = self.metrics.reasoning_metrics\n",
        "        communication_metrics = self.metrics.communication_metrics\n",
        "        autonomy_metrics = self.metrics.autonomy_metrics\n",
        "\n",
        "        return {\n",
        "            'Task Performance Metrics': {\n",
        "                'Success Rate': (task_metrics['successful_requests'] / max(1, task_metrics['total_requests'])) * 100,\n",
        "                'Average Response Time': statistics.mean(task_metrics['response_times']) if task_metrics['response_times'] else 0,\n",
        "                'Average Accuracy': statistics.mean(task_metrics['accuracy_scores']) if task_metrics['accuracy_scores'] else 0,\n",
        "                'Total Requests': task_metrics['total_requests']\n",
        "            },\n",
        "\n",
        "            'Reasoning & Planning Metrics': {\n",
        "                'City Extraction Success Rate': (reasoning_metrics['city_extraction_success'] / max(1, reasoning_metrics['city_extraction_attempts'])) * 100,\n",
        "                'Average Response Relevance': statistics.mean(reasoning_metrics['response_relevance']) if reasoning_metrics['response_relevance'] else 0\n",
        "            },\n",
        "\n",
        "            'Interaction & Communication Metrics': {\n",
        "                'Average Response Length': statistics.mean(communication_metrics['response_lengths']) if communication_metrics['response_lengths'] else 0,\n",
        "                'Average Clarity Score': statistics.mean(communication_metrics['clarity_scores']) if communication_metrics['clarity_scores'] else 0\n",
        "            },\n",
        "\n",
        "            'Autonomy & Robustness Metrics': {\n",
        "                'Error Recovery Rate': (autonomy_metrics['error_recovery_success'] / max(1, autonomy_metrics['error_recovery_attempts'])) * 100,\n",
        "                'Fallback Usage Count': autonomy_metrics['fallback_usage'],\n",
        "                'API Errors Handled': autonomy_metrics['api_error_handling']\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def print_performance_report(self):\n",
        "        \"\"\"Print a formatted performance report\"\"\"\n",
        "        report = self.get_performance_report()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"          WEATHER AGENT PERFORMANCE REPORT\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for category, metrics in report.items():\n",
        "            print(f\"\\nüìä {category}:\")\n",
        "            print(\"-\" * 40)\n",
        "            for metric, value in metrics.items():\n",
        "                if isinstance(value, float):\n",
        "                    if 'Rate' in metric or 'Accuracy' in metric or 'Score' in metric:\n",
        "                        print(f\"  {metric}: {value:.2f}{'%' if 'Rate' in metric else ''}\")\n",
        "                    else:\n",
        "                        print(f\"  {metric}: {value:.3f}s\" if 'Time' in metric else f\"  {metric}: {value:.3f}\")\n",
        "                else:\n",
        "                    print(f\"  {metric}: {value}\")\n",
        "\n",
        "# Interactive mode with metrics\n",
        "def interactive_weather_chat_with_metrics():\n",
        "    \"\"\"Start an interactive weather chat session with metrics tracking\"\"\"\n",
        "    print(\"Setting up Weather Agent with Metrics...\")\n",
        "\n",
        "    # Initialize agent with your API key\n",
        "    agent = OllamaWeatherAgent(weather_api_key=\"6ad9ca56bbc9040af5c4c4b0ca34bfb5\")\n",
        "\n",
        "    print(\"\\nüå§Ô∏è Weather Agent with Metrics is ready!\")\n",
        "    print(\"Ask me about weather in any city. Type 'quit' to exit, 'report' for metrics.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nYou: \").strip()\n",
        "\n",
        "        if user_input.lower() in ['quit', 'exit', 'bye']:\n",
        "            print(\"\\nFinal Performance Report:\")\n",
        "            agent.print_performance_report()\n",
        "            print(\"Goodbye! Stay weather-aware! üåà\")\n",
        "            break\n",
        "\n",
        "        if user_input.lower() == 'report':\n",
        "            agent.print_performance_report()\n",
        "            continue\n",
        "\n",
        "        if not user_input:\n",
        "            continue\n",
        "\n",
        "        print(\"Agent: \", end=\"\")\n",
        "        response, metrics = agent.chat_about_weather(user_input)\n",
        "        print(response)\n",
        "\n",
        "        # Show quick metrics for this interaction\n",
        "        if metrics['success']:\n",
        "            print(f\"   ‚ö° Response time: {metrics['response_time']:.2f}s | \"\n",
        "                  f\"Relevance: {metrics['relevance_score']:.2f} | \"\n",
        "                  f\"Clarity: {metrics['clarity_score']:.2f}\")\n"
      ],
      "metadata": {
        "id": "U_sJVkOXsARq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run interactive mode with metrics\n",
        "    interactive_weather_chat_with_metrics()\n",
        "\n",
        "    # Or run batch tests\n",
        "    # run_batch_tests()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UE-F_g-sJFL",
        "outputId": "6d63d1a4-7410-47d1-a755-f4bafcc96284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up Weather Agent with Metrics...\n",
            "Pulling llama3.1 model...\n",
            "Model llama3.1 ready!\n",
            "\n",
            "üå§Ô∏è Weather Agent with Metrics is ready!\n",
            "Ask me about weather in any city. Type 'quit' to exit, 'report' for metrics.\n",
            "--------------------------------------------------\n",
            "\n",
            "You: what is the weather in banglore?\n",
            "Agent: The current weather in Bengaluru is overcast with a temperature of 27.54¬∞C (feels like 29.59¬∞C). It's a pretty pleasant day out there!\n",
            "\n",
            "**Direct Answer:** The weather in Bangalore is overcast.\n",
            "\n",
            "**Relevant Advice:**\n",
            "Given the overcast conditions and relatively high humidity, I'd recommend dressing in light, breathable clothing that'll help you stay comfortable. A lightweight scarf or umbrella might come in handy if it decides to rain. As for activities, why not take a stroll around Lalbagh Gardens or Cubbon Park? The overcast skies will provide some respite from the heat, and you can enjoy the lush greenery without worrying about the sun beating down on you.\n",
            "\n",
            "Stay dry and stay cool!\n",
            "   ‚ö° Response time: 10.85s | Relevance: 0.87 | Clarity: 0.70\n",
            "\n",
            "You: report\n",
            "\n",
            "============================================================\n",
            "          WEATHER AGENT PERFORMANCE REPORT\n",
            "============================================================\n",
            "\n",
            "üìä Task Performance Metrics:\n",
            "----------------------------------------\n",
            "  Success Rate: 100.00%\n",
            "  Average Response Time: 10.851s\n",
            "  Average Accuracy: 1.00\n",
            "  Total Requests: 1\n",
            "\n",
            "üìä Reasoning & Planning Metrics:\n",
            "----------------------------------------\n",
            "  City Extraction Success Rate: 100.00%\n",
            "  Average Response Relevance: 0.867\n",
            "\n",
            "üìä Interaction & Communication Metrics:\n",
            "----------------------------------------\n",
            "  Average Response Length: 690\n",
            "  Average Clarity Score: 0.70\n",
            "\n",
            "üìä Autonomy & Robustness Metrics:\n",
            "----------------------------------------\n",
            "  Error Recovery Rate: 0.00%\n",
            "  Fallback Usage Count: 0\n",
            "  API Errors Handled: 0\n",
            "\n",
            "You: weather in london\n",
            "Agent: The current weather in London is overcast with a temperature of 18.24¬∞C and feels like 18.18¬∞C. It's a pretty mild day, but don't let that fool you - it's still quite humid at 79%.\n",
            "\n",
            "As for advice, I'd recommend dressing in layers to stay comfortable. You might want to pack a lightweight rain jacket or umbrella just in case the clouds decide to unleash some showers.\n",
            "\n",
            "If you're planning on venturing out, consider taking advantage of London's many indoor attractions like museums, galleries, or shopping centers. The overcast skies and humidity might not be ideal for outdoor activities, but there's plenty to explore indoors.\n",
            "\n",
            "Have a great day in London!\n",
            "   ‚ö° Response time: 4.81s | Relevance: 1.00 | Clarity: 0.80\n",
            "\n",
            "You: report\n",
            "\n",
            "============================================================\n",
            "          WEATHER AGENT PERFORMANCE REPORT\n",
            "============================================================\n",
            "\n",
            "üìä Task Performance Metrics:\n",
            "----------------------------------------\n",
            "  Success Rate: 100.00%\n",
            "  Average Response Time: 7.832s\n",
            "  Average Accuracy: 1.00\n",
            "  Total Requests: 2\n",
            "\n",
            "üìä Reasoning & Planning Metrics:\n",
            "----------------------------------------\n",
            "  City Extraction Success Rate: 100.00%\n",
            "  Average Response Relevance: 0.933\n",
            "\n",
            "üìä Interaction & Communication Metrics:\n",
            "----------------------------------------\n",
            "  Average Response Length: 673\n",
            "  Average Clarity Score: 0.75\n",
            "\n",
            "üìä Autonomy & Robustness Metrics:\n",
            "----------------------------------------\n",
            "  Error Recovery Rate: 0.00%\n",
            "  Fallback Usage Count: 0\n",
            "  API Errors Handled: 0\n"
          ]
        }
      ]
    }
  ]
}